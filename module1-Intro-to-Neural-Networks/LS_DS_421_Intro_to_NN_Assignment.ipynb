{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer:The Input Layer is what receives input from our dataset. Sometimes it is called the visible layer because it's the only part that is exposed to our data and that our data interacts with directly. Typically node maps are drawn with one input node for each of the different inputs/features/columns of our dataset that will be passed to the network. \n",
    "### Hidden Layer:Layers after the input layer are called Hidden Layers. This is because they cannot be accessed except through the input layer. They're inside of the network and they perform their functions, but we don't directly interact with them. The simplest possible network is to have a single neuron in the hidden layer that just outputs the value. \"Deep Learning\" apart from being a big buzzword simply means that we are using a Neural Network that has multiple hidden layers.\n",
    "### Output Layer:The final layer is called the Output Layer. The purpose of the output layer is to output a vector of values that is in a format that is suitable for the type of problem that we're trying to address. Typically the output value is modified by an \"activation function\" to transform it into a format that makes sense for our context, here's a couple of examples:\n",
    "### Neuron:receive inputs and pass on their signal to the next layer of nodes if a certain threshold is reached\n",
    "### Weight:modiefies the input\n",
    "### Activation Function:In Neural Networks, each node has an activation function. Each node in a given layer typically has the same activation function. These activation functions are the biggest piece of neural networks that have been inspired by actual biology. The activation function decides whether a cell \"fires\" or not. Sometimes it is said that the cell is \"activated\" or not. In Artificial Neural Networks activation functions decide how much signal to pass onto the next layer. This is why they are sometimes referred to as transfer functions because they determine how much signal is transferred to the next layer.\n",
    "### Node Map:  a visual diagram of the architecture or \"topology\" of our neural network. It's kind of like a flow chart in that it shows the path from inputs to outputs. They are usually color coded and help us understand at a very high level, some of the differences in architecture between kinds of neural networks.\n",
    "![A Mapping](http://jalammar.github.io/images/NNs_formula_no_bias.png)\n",
    "![Neural Network Zoo](http://www.asimovinstitute.org/wp-content/uploads/2016/09/neuralnetworks.png)\n",
    "### Perceptron:A perceptron is just a single node or neuron of a neural network with nothing else. It can take any number of inputs and spit out an output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(812)\n",
    "\n",
    "inputs = np.array([\n",
    "    [0,0,1],\n",
    "    [1,0,1],\n",
    "    [0,1,1],\n",
    "    [1,1,0]\n",
    "])\n",
    "\n",
    "correct_outputs= [[0],[1],[0],[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nand_percept(x1, x2):\n",
    "    return (x1 and x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset like: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "- [Titanic](https://raw.githubusercontent.com/ryanleeallred/datasets/master/titanic.csv)\n",
    "- [A two-class version of the Iris dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/Iris.csv)\n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "class Perceptron(object):\n",
    "  def __init__(self, rate = 0.01, niter = 10):\n",
    "    self.rate = rate\n",
    "    self.niter = niter\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    \"\"\"Fit training data\n",
    "    X : Training vectors, X.shape : [#samples, #features]\n",
    "    y : Target values, y.shape : [#samples]\n",
    "    \"\"\"\n",
    "\n",
    "    # weights\n",
    "    self.weight = np.zeros(1 + X.shape[1])\n",
    "\n",
    "    # Number of misclassifications\n",
    "    self.errors = []  # Number of misclassifications\n",
    "\n",
    "    for i in range(self.niter):\n",
    "      err = 0\n",
    "      for xi, target in zip(X, y):\n",
    "        delta_w = self.rate * (target - self.predict(xi))\n",
    "        self.weight[1:] += delta_w * xi\n",
    "        self.weight[0] += delta_w\n",
    "        err += int(delta_w != 0.0)\n",
    "      self.errors.append(err)\n",
    "    return self\n",
    "\n",
    "  def net_input(self, X):\n",
    "    \"\"\"Calculate net input\"\"\"\n",
    "    return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\"Return class label after unit step\"\"\"\n",
    "    return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  survived  pclass     sex   age  sibsp  parch     fare embarked  \\\n",
       "0           0         0       3    male  22.0      1      0   7.2500        S   \n",
       "1           1         1       1  female  38.0      1      0  71.2833        C   \n",
       "2           2         1       3  female  26.0      0      0   7.9250        S   \n",
       "3           3         1       1  female  35.0      1      0  53.1000        S   \n",
       "4           4         0       3    male  35.0      0      0   8.0500        S   \n",
       "\n",
       "   class    who  adult_male deck  embark_town alive  alone  \n",
       "0  Third    man        True  NaN  Southampton    no  False  \n",
       "1  First  woman       False    C    Cherbourg   yes  False  \n",
       "2  Third  woman       False  NaN  Southampton   yes   True  \n",
       "3  First  woman       False    C  Southampton   yes  False  \n",
       "4  Third    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['pclass', 'sex', 'fare', 'sibsp', 'parch', 'age']].replace({'male': 0, 'female': 1}).values\n",
    "y = np.array(df['survived'].replace({0:-1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Perceptron at 0x155e2d557b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percept = Perceptron(0.01, 50)\n",
    "percept.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(percept.errors) + 1), percept.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
